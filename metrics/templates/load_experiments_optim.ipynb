{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loading Experiment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook, we start by loading the data collected while running different experiment-wares, and perform some preprocessing on this data to allow its use for further analysis in dedicated notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We first need to import the modules we need to load the data.\n",
    "In particular, we must obviously import *Metrics-Wallet*, which we will use to deal with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T17:26:58.851247Z",
     "start_time": "2021-11-07T17:26:58.847902Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from metrics.wallet import BasicAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The next step is to read the data from the log files produced by our different experiment-wares.\n",
    "This data is described in the file [`{{ config_file }}.yml`](config/{{ config_file }}.yml), and automatically parsed by *Metrics-Scalpel* to create a `BasicAnalysis` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T17:27:53.817744Z",
     "start_time": "2021-11-07T17:27:00.267087Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "analysis = BasicAnalysis(input_file='config/{{ config_file }}.yml', log_level='WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `BasicAnalysis` object instantiated above provides elementary and general methods for preprocessing our data before actually analyzing the results (which will require more specific methods as it can be seen in the dedicated notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An important thing to do now is to visualize the collected data, to make sure that everything was properly read.\n",
    "This can be achieved by looking at the data-frame that has been built inside the `BasicAnalysis` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis.data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TODO: CHECK THAT EVERYTHING IS INDEED OK BEFORE PREPROCESSING THE DATA!**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before making any change to the data, we keep a copy of the analysis in its current state to allow rolling back our changes if needed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analysis.export('.cache-original')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## More meaningful names for experiment-wares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Currently, the names of the experiment-wares correspond to those extracted by *Metrics-Scalpel*.\n",
    "While they are sufficient to discriminate them in the analysis, they are not necessarily meaningful.\n",
    "It is possible to replace them by more descriptive names, that may even contain LaTeX code if you want pretty names in your papers.\n",
    "To do so, replace the content of the following dictionary by using the previous name of each experiment-ware as key and its new name as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "name_map = {\n",
    "    xp_ware: xp_ware for xp_ware in analysis.experiment_wares\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Based on the map above, we can easily replace the name of the experiment-wares as follows.\n",
    "For convenience, note that we keep a copy of the previous experiment-ware names, as they may be easier to handle programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis = analysis.add_variable(\n",
    "    new_var='raw_experiment_ware',\n",
    "    function=lambda xp: xp['experiment_ware']\n",
    ").add_variable(\n",
    "    new_var='experiment_ware',\n",
    "    function=lambda xp: name_map[xp['experiment_ware']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General data preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TODO: ADD HERE ALL THE CODE YOU NEED TO FIX POTENTIAL PROBLEMS WITH THE COLLECTED DATA (E.G., MISSING VALUES, TYPOS, ETC.).**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now check that the changes have been taken into account by having a look to the data-frame of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "analysis.data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Checking the success and consistency of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "During our analysis, we will need to know whether a given experiment was successful.\n",
    "To this end, we will need to have a look to different columns of the analysis, that allow to identify the experiment-ware's answer.\n",
    "You may need to edit them if you do not have given the same names in your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The decision given by the experiment-ware w.r.t. the satisfiability of the input.\n",
    "decision = 'decision'\n",
    "\n",
    "# Whether the input problem is a minimization or maximization problem.\n",
    "objective = 'objective'\n",
    "\n",
    "# The best bound found by the experiment-ware on the input.\n",
    "best_bound = 'best_bound'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function below will be used to check that the solver terminated with its final decision."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def is_success(xp):\n",
    "    \"\"\"\n",
    "    This function checks that an experiment-ware either proved the optimality of its best\n",
    "    bound within the time limit, or proved the input to be unsatisfiable.\n",
    "    \"\"\"\n",
    "    return xp[decision] == 'OPTIMUM FOUND' or xp[decision] == 'UNSATISFIABLE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To make sure that our experiments are consistent, we also need to compare the results obtained by the different experiment-wares.\n",
    "The function below checks that if different optimization solvers claim to have found an optimal value, this value must be the same for all solvers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def is_consistent_by_input(df_input):\n",
    "    \"\"\"\n",
    "    This function checks that there is no contradictory answers between the solvers,\n",
    "    both regarding the answer they give w.r.t. the satisfiability of their input and\n",
    "    the best bound they have been able to find.\n",
    "    \"\"\"\n",
    "    # Checking the decision of the solvers.\n",
    "    decisions = df_input[decision].unique()\n",
    "    if 'OPTIMUM FOUND' in decisions and 'UNSATISFIABLE' in decisions:\n",
    "        # A solver has found an optimal solution while another proved unsatisfiability.\n",
    "        return False\n",
    "    if 'SATISFIABLE' in decisions and 'UNSATISFIABLE' in decisions:\n",
    "        # A solver has found a solution while another proved unsatisfiability.\n",
    "        return False\n",
    "\n",
    "    # Checking that at most one optimal value exists.\n",
    "    best_values_for_complete_search = df_input[df_input[decision] == 'OPTIMUM FOUND'][best_bound].unique()\n",
    "    if len(best_values_for_complete_search) == 0:\n",
    "        # No solver has proved optimality, so we cannot check anything else.\n",
    "        return True\n",
    "    if len(best_values_for_complete_search) > 1:\n",
    "        # Several distinct optimal values have been proven, which is not possible.\n",
    "        return False\n",
    "\n",
    "    # Checking that there is no better value than the optimal (i.e., minimal or maximal) one.\n",
    "    if 'min' in str(df_input[objective].unique()[0]).lower():\n",
    "        best_global_value = df_input[best_bound].min()\n",
    "    else:\n",
    "        best_global_value = df_input[best_bound].max()\n",
    "    return pd.isnull(best_global_value) or best_values_for_complete_search[0] == best_global_value"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now use the functions above to check the consistency of the different experiments in the analysis."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis.check_success(is_success)\n",
    "analysis.check_input_consistency(is_consistent_by_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TODO: CHECK THAT NO WARNING IS RAISED.**\n",
    "\n",
    "**TODO: LOOK AT THE FOLLOWING TABLE TO UNDERSTAND WHY WARNINGS WERE RAISED.**\n",
    "\n",
    "**TODO: IN BOTH CASES, ADD A COMMENT HERE TO CONFIRM THAT THERE IS NO PROBLEM OR WHY THERE ARE PROBLEMS.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis.error_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Summary and export of the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now give a summary of the analysis, that we obtain through the following table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis.description_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, the analysis is exported, both to share the data to allow the reproducibility of the analysis, and to reuse it in other notebooks dedicated to more specific analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T17:31:00.310070Z",
     "start_time": "2021-11-07T17:31:00.293572Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis.export('.cache')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
