{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "677a81fe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Analysis of the Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9948ee",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook, we now analyze the performance of the different experiment-wares in terms of runtime.\n",
    "More precisely, we only compare the experiment-wares based on the time they spent before completing their task (and thus, experiments in which the timeout is reached are considered unsuccessful, whatever their outcome)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28056756",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa448e6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As usual, we start by importing the needed classes and functions from *Metrics-Wallet*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79d77f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from metrics.wallet import BasicAnalysis, DecisionAnalysis, LineType\n",
    "from metrics.wallet import find_best_cpu_time_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ad912",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading the data of the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd842c98",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In a [dedicated notebook]({{ load_notebook }}.ipynb), we already read and preprocessed the data collected during our experiments.\n",
    "We can now simply reload the cached `BasicAnalysis` to retrieve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954fcd1b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "basic_analysis = BasicAnalysis.import_from_file('.cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921c2dad",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since we now want to perform a more specific analysis, we need to create a `DecisionAnalysis` that will provide methods dedicated to the analysis of the runtime of experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109625e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis = DecisionAnalysis(basic_analysis=basic_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e6bea1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Virtual Best Experiment-Ware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc50e32",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The *Virtual Best Experiment-Ware* (or VBEW) is an experiment-ware that does not really exist.\n",
    "Its runtime on a particular input is that of the fastest experiment-ware that was run on that input (even though one could define a VBEW based on other criteria).\n",
    "If one had an oracle to select the best experiment-ware for a particular input, and then run the experiment-ware on this input, its runtime would be that of the VBEW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed634c",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis = analysis.add_virtual_experiment_ware(function=find_best_cpu_time_input, name='VBEW')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d421866",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now compute the contribution of each experiment-ware to the VBEW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee00cde",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis.remove_experiment_wares(['VBEW'])\\\n",
    "        .contribution_table(deltas=(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f531527d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let us describe how to read this table.\n",
    "In the first column, we can see for each experiment-ware the number of inputs for which the runtime of the experiment-ware is equal to that of the VBEW.\n",
    "In the second column (resp. third column), we can see for each experiment-ware the number of inputs for which the experiment-ware is at least 1 second faster (resp. 10 seconds faster) than any other experiment-ware.\n",
    "Finally, in the fourth column, we can see the number of inputs for which this experiment-ware is the only one to run until completion (and thus, all other experiment-wares reached the time limit on this input)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For a more visual representation of these contributions, we can represent the information provided in the table above with a bar plot.\n",
    "This plot shows for each solver the number of times the runtime of this solver is equal to that of the VBEW."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analysis.marginal_contribution()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "091ac4a5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Overview of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c1349",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An overview of the results can easily be obtained using a so-called *cactus-plot*, which is a figure that is particularly popular in the SAT or CP communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8608cd6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis.cactus_plot(\n",
    "    cactus_col='cpu_time',\n",
    "    show_marker=False,\n",
    "\n",
    "    title='Cactus-plot',\n",
    "    x_axis_name='Number of solved inputs',\n",
    "    y_axis_name='Time (s)',\n",
    "\n",
    "    color_map={ 'VBEW': '#000000' },\n",
    "    style_map={ 'VBEW': LineType.DASH_DOT },\n",
    "\n",
    "    dynamic=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131d6ce1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "On this plot, we can easily read for each experiment-ware the number of inputs on which it can run until completion within a certain time limit.\n",
    "In particular, the more an experiment-ware is to the right, the faster it is in general."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TODO: ADD HERE AN INTERPRETATION FOR THIS CACTUS-PLOT!**\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "d91b2838",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Another way to get an overview of the results is to use the *cumulative distribution function* (CDF), which may be seen as a cactus-plot in which the axes have been switched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce129b0",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis.cdf_plot(\n",
    "    cdf_col='cpu_time',\n",
    "    show_marker=False,\n",
    "    normalized=True,\n",
    "\n",
    "    title='CDF',\n",
    "    x_axis_name='Time (s)',\n",
    "    y_axis_name='Percentage of solved inputs',\n",
    "\n",
    "    color_map={ 'VBEW': '#000000' },\n",
    "    style_map={ 'VBEW': LineType.DASH_DOT },\n",
    "\n",
    "    dynamic=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a03d2e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The interpretation of this plot is similar to that of a cactus-plot.\n",
    "One of the advantage of this representation is that the order of the lines in the plot is the same as that of the legend, and thus best experiment-wares are on the top.\n",
    "Additionally, it has more connections with the theory of statistics (while cactus-plots are not so meaningful outside the community)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce825d3f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Talking about statistics, box-plots can also be used to have an overview of the distribution of the runtime of the different experiment-wares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e174ccd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis.box_plot(\n",
    "    box_by='experiment_ware',\n",
    "    box_col='cpu_time',\n",
    "\n",
    "    title='Box-plots of the runtime',\n",
    "\n",
    "    dynamic=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ea916a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TODO: ADD HERE AN INTERPRETATION FOR THESE BOXPLOTS!**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Numerical results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To get more information about the statistics of our experiments, let us refer to the following table."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analysis.stat_table(\n",
    "    commas_for_number=True,\n",
    "    dollars_for_number=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us describe the content of this table, for each considered experiment-ware:\n",
    "\n",
    "- The column `count` is the number of inputs solved by the experiment-ware.\n",
    "- The column `sum` is the time taken by the experiment-ware to run on all inputs (including timeouts).\n",
    "- The columns `PARx` are equivalent to `sum` but add a penalty of `x` times the timeout to failed experiments (*PAR* stands for *Penalized Average Runtime*).\n",
    "- The column `common count` is the number of inputs commonly solved by all experiment-wares.\n",
    "- The column `common sum` is the time taken by the (current) experiment-ware to solve the commonly solved inputs.\n",
    "- The column `uncommon count` is the number of inputs solved by the experiment-ware without considering common ones (which are considered as *easy*).\n",
    "- The column `total` is the total number of experiments run with the experiment-ware."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TODO: ADD AN INTERPRETATION OF THE RESULTS IN THE TABLE ABOVE.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us now consider another table, which provides for each input and for each experiment-ware the information relative to a particular variable in the analysis, for instance the `cpu_time` of the experiment-ware on an input."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analysis.pivot_table(\n",
    "    index='input',\n",
    "    columns='experiment_ware',\n",
    "    values='cpu_time',\n",
    "    commas_for_number=True,\n",
    "    dollars_for_number=True\n",
    ")#.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TODO: ADD HERE AN INTERPRETATION OF THE TABLE ABOVE.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "1d51f8a1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pairwise comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99745cc5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that we have an overview of the results, we can make a pairwise comparison of the experiment-wares, to have a closer look at their behavior.\n",
    "We can do so by drawing so-called *scatter-plots*."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we need to select two of the experiment-wares among those run during the experiments."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xp_ware_x = analysis.experiment_wares[0]\n",
    "xp_ware_y = analysis.experiment_wares[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the experiment-wares have been selected, we can draw a scatter-plot that compares the runtime of both solvers on each input.\n",
    "Here, each point is an input, and the x-axis and y-axis correspond to the runtime of `xp_ware_x` and `xp_ware_y` on this input, respectively."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da20e8f",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis.scatter_plot(\n",
    "    xp_ware_x,\n",
    "    xp_ware_y,\n",
    "\n",
    "    scatter_col='cpu_time',\n",
    "    title=f'Comparison between {xp_ware_x} and {xp_ware_y}',\n",
    "\n",
    "    x_min=1,\n",
    "    x_max={{ timeout }},\n",
    "    y_min=1,\n",
    "    y_max={{ timeout }},\n",
    "\n",
    "    logx=True,\n",
    "    logy=True,\n",
    "\n",
    "    dynamic=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TODO: ADD HERE AN INTERPRETATION FOR THIS SCATTER-PLOT!**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While the analysis presented in this template only presents one scatter-plot for demonstration purposes, it may be useful for you to draw more scatter-plots, based on your needs.\n",
    "In fact, all pairwise comparisons between two experiment-wares could be visualized using scatter-plots."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
