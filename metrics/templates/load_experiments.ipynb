{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loading Experiment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook, we start by loading the data collected while running different experiment-wares, and perform some preprocessing on this data to allow its use for further analysis in dedicated notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We first need to import the modules we need to load the data.\n",
    "In particular, we must obviously import *Metrics-Wallet*, which we will use to deal with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T17:26:58.851247Z",
     "start_time": "2021-11-07T17:26:58.847902Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from metrics.wallet import BasicAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The next step is to read the data from the log files produced by our different experiment-wares.\n",
    "This data is described in the file [`{{ config_file }}.yml`](config/{{ config_file }}.yml), and automatically parsed by *Metrics-Scalpel* to create a `BasicAnalysis` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T17:27:53.817744Z",
     "start_time": "2021-11-07T17:27:00.267087Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis = BasicAnalysis(input_file='config/{{ config_file }}.yml', log_level='WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `BasicAnalysis` object instantiated above provides elementary and general methods for preprocessing our data before actually analyzing the results (which will require more specific methods as it can be seen in the dedicated notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An important thing to do now is to visualize the collected data, to make sure that everything was properly read.\n",
    "This can be achieved by looking at the data-frame that has been built inside the `BasicAnalysis` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis.data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TODO: CHECK THAT EVERYTHING IS INDEED OK BEFORE PREPROCESSING THE DATA!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## More meaningful names for experiment-wares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Currently, the names of the experiment-wares correspond to those extracted by *Metrics-Scalpel*.\n",
    "While they are sufficient to discriminate them in the analysis, they are not necessarily meaningful.\n",
    "It is possible to replace them by more descriptive names, that may even contain LaTeX code if you want pretty names in your papers.\n",
    "To do so, replace the content of the following dictionary by using the previous name of each experiment-ware as key and its new name as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "name_map = {\n",
    "    xp_ware: xp_ware for xp_ware in analysis.experiment_wares()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Based on the map above, we can easily replace the name of the experiment-wares as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis = analysis.add_variable(\n",
    "    new_var='experiment_ware', \n",
    "    function=lambda xp: name_map[xp['experiment_ware']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General data preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TODO: ADD HERE ALL THE CODE YOU NEED TO FIX POTENTIAL PROBLEMS WITH THE COLLECTED DATA (E.G., MISSING VALUES, TYPOS, ETC.).**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now check that the changes have been taken into account by having a look to the data-frame of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "analysis.data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Checking the success and consistency of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "During our analysis, we will need to know whether a given experiment was successful.\n",
    "As an example, we provide below the code to check the success of an optimization solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def is_success(xp):\n",
    "    \"\"\"\n",
    "    This function checks that a solver either proved the optimality of its best\n",
    "    bound within the time limit, or proved the input to be unsatisfiable.\n",
    "    \"\"\"\n",
    "    return xp['decision'] == 'OPTIMUM FOUND' or xp['decision'] == 'UNSATISFIABLE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To make sure that our experiments are consistent, we also need to compare the results obtained by the different experiment-wares.\n",
    "As an example, we provide below the code to check that if different optimization solvers claim to have found an optimal value, this value must be the same for all solvers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def is_consistent_by_input(df_input):\n",
    "    \"\"\"\n",
    "    This function checks that the pairwise comparison between two different\n",
    "    optimal bounds found on the same input is small enough to consider these bounds as consistent.\n",
    "    \"\"\"\n",
    "    # Checking the decision of the solvers.\n",
    "    decisions = df_input['decision'].unique()\n",
    "    if 'OPTIMUM FOUND' in decisions and 'UNSATISFIABLE' in decisions:\n",
    "        # A solver has found an optimal solution while another proved unsatisfiability.\n",
    "        return False\n",
    "    if 'SATISFIABLE' in decisions and 'UNSATISFIABLE' in decisions:\n",
    "        # A solver has found a solution while another proved unsatisfiability.\n",
    "        return False\n",
    "\n",
    "    # Checking that at most one optimal value exists.\n",
    "    best_values_for_complete_search = df_input[df_input['success']]['best_bound'].unique()\n",
    "\n",
    "    # Checking that there is no better value than the optimal one.\n",
    "    if df_input['objective'].unique()[0] == 'min':\n",
    "        best_global_value = df_input['best_bound'].min()\n",
    "    else:\n",
    "        best_global_value = df_input['best_bound'].max()\n",
    "\n",
    "    return best_global_value is None or \\\n",
    "           len(best_values_for_complete_search) <= 1 and \\\n",
    "           best_values_for_complete_search[0] != best_global_value"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now use the functions above to check the consistency of the different experiments in the analysis."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis.check_success(is_success)\n",
    "analysis.check_input_consistency(is_consistent_by_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TODO: CHECK THAT NO WARNING IS RAISED.**\n",
    "\n",
    "**TODO: LOOK AT THE FOLLOWING TABLE TO UNDERSTAND WHY WARNINGS WERE RAISED.**\n",
    "\n",
    "**TODO: IN BOTH CASES, ADD A COMMENT HERE TO CONFIRM THAT THERE IS NO PROBLEM OR WHY THERE ARE PROBLEMS.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis.error_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Summary and export of the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now give a summary of the analysis, that we obtain through the following table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis.description_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, the analysis is exported, both to share the data to allow the reproducibility of the analysis, and to reuse it in other notebooks dedicated to more specific analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T17:31:00.310070Z",
     "start_time": "2021-11-07T17:31:00.293572Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis.export('.cache')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}